import pandas as pd
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer

# 讀取 Excel 文件
filename = "processed_專利文本資料.xlsx"
df = pd.read_excel(filename, header=None)  # header=None 表示沒有列名

# 手動設置列名
df.columns = ["Text"]  # 假設數據在第一列
print("數據框預覽：")
print(df.head())

# 確保文本數據存在
texts = df["Text"].dropna().tolist()

# 加載 Sentence-BERT 模型和 Tokenizer
embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")

# 定義分塊函數
def split_into_chunks(text, max_length=512):
    tokens = tokenizer.tokenize(text)
    chunks = [
        tokenizer.convert_tokens_to_string(tokens[i:i + max_length])
        for i in range(0, len(tokens), max_length)
    ]
    return chunks

# 分塊文本並嵌入
chunked_data = []
for idx, text in enumerate(texts):
    chunks = split_into_chunks(text, max_length=512)
    for chunk in chunks:
        chunked_data.append({"chunk": chunk, "patent_id": idx})

chunked_df = pd.DataFrame(chunked_data)

# 嵌入每個分塊
chunked_df["embedding"] = chunked_df["chunk"].apply(lambda x: embedding_model.encode(x))
final_embeddings = chunked_df["embedding"].tolist()

print(f"嵌入完成，共生成 {len(final_embeddings)} 條專利嵌入向量。")



from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def mmr_selection(topics, embeddings, num_topics=10, lambda_param=0.5):
    # topics: 主題列表
    # embeddings: 主題嵌入向量
    # num_topics: 最終選擇的主題數量
    # lambda_param: MMR中的參數，平衡相關性和多樣性

    selected_topics = []
    selected_embeddings = []

    # 初始化，選擇第一個主題
    selected_topics.append(topics[0])
    selected_embeddings.append(embeddings[0])

    # 遍歷剩下的主題並選擇
    for _ in range(1, num_topics):
        remaining_topics = list(set(topics) - set(selected_topics))
        remaining_embeddings = [embeddings[topics.index(topic)] for topic in remaining_topics]

        # 計算與已選主題的相似度
        similarities = cosine_similarity(selected_embeddings, remaining_embeddings)

        # 計算 MM-R 分數
        mmr_scores = (1 - lambda_param) * np.max(similarities, axis=0) - lambda_param * np.mean(similarities, axis=0)

        # 選擇最大 MM-R 分數的主題
        best_idx = np.argmax(mmr_scores)
        selected_topics.append(remaining_topics[best_idx])
        selected_embeddings.append(remaining_embeddings[best_idx])

    return selected_topics
# 假設您已經得到了 BERTopic 的主題和嵌入向量
topics, embeddings = chunked_df["chunk"].tolist(), np.array(chunked_df["embedding"].tolist())

# 使用 BERTopic 進行主題建模
topic_model = BERTopic()
topics, probs = topic_model.fit_transform(texts, embeddings=embeddings)

# 打印原始的主題信息
print("主題建模完成！")
print(topic_model.get_topic_info())

# 使用 MMR 選擇主題
selected_topics = mmr_selection(topics, embeddings, num_topics=10, lambda_param=0.5)

# 打印選擇後的主題
print("選擇後的主題：")
print(selected_topics)

topic_info = topic_model.get_topic_info()

# 使用正確的變數名 selected_topics
selected_topics_info = topic_info[topic_info["Topic"].isin(selected_topics)]

# 打印篩選後的主題信息
print(selected_topics_info)


